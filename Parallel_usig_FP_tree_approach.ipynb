{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fockUFPbzfz",
        "outputId": "f99c7546-e03d-4a67-c6f0-6256ffceaf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 42.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 112 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 133 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 143 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 153 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 174 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 184 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 194 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 215 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 225 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 235 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 256 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 266 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 276 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 286 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 296 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 307 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 317 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 327 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 337 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 348 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 358 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 368 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 378 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 389 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 399 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 409 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 419 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 430 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 439 kB 27.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet mrjob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvuelEeGcwUJ",
        "outputId": "e898c746-003b-4e97-8d32-3d9565b8bde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file temp.py\n",
        "\n",
        "class FPNode:\n",
        "    def __init__(self, item, count, parent):\n",
        "        self.item = item\n",
        "        self.count = count\n",
        "        self.parent = parent\n",
        "        self.children = {}\n",
        "        self.link = None\n",
        "\n",
        "    def add(self, transaction, item_freq):\n",
        "        if transaction:\n",
        "            item = transaction[0]\n",
        "            child = self.children.get(item)\n",
        "            if child is None:\n",
        "                child = FPNode(item, item_freq[item], self)\n",
        "                self.children[item] = child\n",
        "                if self.link is not None:\n",
        "                    child.link = self.link.children.get(item)\n",
        "                    self.link.children[item] = child\n",
        "                else:\n",
        "                    child.link = None\n",
        "            child.count += 1\n",
        "            child.add(transaction[1:], item_freq)\n",
        "\n",
        "    def prefix_paths(self, item):\n",
        "        paths = []\n",
        "        if self.item == item:\n",
        "            paths.append([self])\n",
        "        for child in self.children.values():\n",
        "            for path in child.prefix_paths(item):\n",
        "                paths.append([self] + path)\n",
        "        return paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGUkNi3nd55B",
        "outputId": "4b814945-2ee4-4121-fa43-c5557c08617e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing temp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file PFP.py\n",
        "from temp import FPNode\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "min_support=2\n",
        "\n",
        "class PFPGrowth(MRJob):\n",
        "    def mapper(self, _, value):\n",
        "        items = value.strip().split()\n",
        "        for item in items:\n",
        "            yield item, 1\n",
        "\n",
        "    def reducer(self, key, value):\n",
        "        count=sum(value)\n",
        "        if(count>=min_support):\n",
        "            yield key, count\n",
        "\n",
        "    def mapper1(self, key, value):\n",
        "        \n",
        "\n",
        "    def reducer1(self, key, value):\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLUXLz-Ub2Kt",
        "outputId": "44594836-0140-4ff1-a3d7-773670147432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing PFP.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUuNPaAr-zrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file temp1.py\n",
        "\n",
        "# class FPNode:\n",
        "#     def __init__(self, value, count, parent):\n",
        "#         self.value = value\n",
        "#         self.count = count\n",
        "#         self.parent = parent\n",
        "#         self.children = []\n",
        "#         self.link = None\n",
        "\n",
        "#     def has_child(self, value):\n",
        "#         for node in self.children:\n",
        "#             if node.value == value:\n",
        "#                 return True\n",
        "#         return False\n",
        "\n",
        "#     def get_child(self, value):\n",
        "#         for node in self.children:\n",
        "#             if node.value == value:\n",
        "#                 return node\n",
        "#         return None\n",
        "\n",
        "#     def add_child(self, value, count=1):\n",
        "#         child = FPNode(value, count, self)\n",
        "#         self.children.append(child)\n",
        "#         return child\n",
        "\n",
        "class FPTree:\n",
        "    def __init__(self, min_support=1):\n",
        "        self.root = FPNode(None, None, None)\n",
        "        self.min_support = min_support\n",
        "        self.header_table = {}\n",
        "\n",
        "    def add(self, items, count=1):\n",
        "        current = self.root\n",
        "        for item in items:\n",
        "            child = current.get_child(item)\n",
        "            if child is not None:\n",
        "                child.count += count\n",
        "            else:\n",
        "                child = current.add_child(item, count)\n",
        "                if item in self.header_table:\n",
        "                    self.update_header(item, child)\n",
        "                else:\n",
        "                    self.header_table[item] = [child, 0]\n",
        "            current = child\n",
        "        current.count += count\n",
        "\n",
        "    def update_header(self, item, node):\n",
        "        previous = self.header_table[item][0]\n",
        "        previous.link = node\n",
        "        self.header_table[item][0] = node\n",
        "\n",
        "    def find_frequent_patterns(self):\n",
        "        patterns = {}\n",
        "        for item in self.header_table:\n",
        "            node = self.header_table[item][0]\n",
        "            while node is not None:\n",
        "                pattern = self.get_pattern(node)\n",
        "                count = node.count\n",
        "                if count >= self.min_support:\n",
        "                    patterns[tuple(pattern)] = count\n",
        "                node = node.link\n",
        "        return patterns\n",
        "\n",
        "    def get_pattern(self, node):\n",
        "        pattern = []\n",
        "        current = node\n",
        "        while current.parent is not None:\n",
        "            pattern.append(current.value)\n",
        "            current = current.parent\n",
        "        return pattern[::-1]\n",
        "\n",
        "    def to_json(self):\n",
        "        # Convert the tree to a JSON object\n",
        "        return {\n",
        "            'min_support': self.min_support,\n",
        "            'root': self.root.to_json(),\n",
        "            'header_table': self.header_table\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def from_json(tree_json):\n",
        "        # Load the tree from a JSON object\n",
        "        tree = FPTree(tree_json['min_support'])\n",
        "        tree.root = FPNode.from_json(tree_json['root'])\n",
        "        tree.header_table = tree_json['header_table']\n",
        "        return tree\n",
        "\n",
        "class FPNode:\n",
        "    def __init__(self, value, count, parent):\n",
        "        self.value = value\n",
        "        self.count = count\n",
        "        self.parent = parent\n",
        "        self.children = []\n",
        "        self.link = None\n",
        "\n",
        "    def has_child(self, value):\n",
        "        for node in self.children:\n",
        "            if node.value == value:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def get_child(self, value):\n",
        "        for node in self.children:\n",
        "            if node.value == value:\n",
        "                return node\n",
        "        return None\n",
        "\n",
        "    def add_child(self, value, count=1):\n",
        "        child = FPNode(value, count, self)\n",
        "        self.children.append(child)\n",
        "        return child\n",
        "\n",
        "    def to_json(self):\n",
        "        # Convert the node to a JSON object\n",
        "        return {\n",
        "            'value': self.value,\n",
        "            'count': self.count,\n",
        "            'children': [node.to_json() for node in self.children]\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def from_json(node_json):\n",
        "        # Load the node from a JSON object\n",
        "        node = FPNode(node_json['value'], node_json['count'], None)\n",
        "        node.children = [FPNode.from_json(child) for child in node_json['children']]\n",
        "        return node\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j1m5EYT-zxY",
        "outputId": "3b8e0e6a-29b0-474e-c5c3-27e59c08211e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing temp1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file PFP1.py\n",
        "from temp1 import FPTree\n",
        "from temp1 import FPNode\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "\n",
        "class MRFPGrowth(MRJob):\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper_get_items,\n",
        "                   reducer=self.reducer_count_items),\n",
        "            MRStep(mapper=self.mapper_sort_counts,\n",
        "                   mapper_init=self.load_frequent_itemsets,\n",
        "                   reducer=self.reducer_build_fp_tree),\n",
        "            MRStep(mapper=self.mapper_find_patterns,\n",
        "                   reducer=self.reducer_output_patterns)\n",
        "        ]\n",
        "\n",
        "    def mapper_get_items(self, _, line):\n",
        "        # Split the input line into a list of items\n",
        "        items = line.split()\n",
        "        # Emit each item in the list with a count of 1\n",
        "        for item in items:\n",
        "            yield item, 1\n",
        "\n",
        "    def reducer_count_items(self, item, counts):\n",
        "        # Sum the counts of the items\n",
        "        total_count = sum(counts)\n",
        "        # Emit the item and its total count\n",
        "        yield item, total_count\n",
        "\n",
        "    def mapper_sort_counts(self, item, count):\n",
        "        # Load the frequent itemsets\n",
        "        frequent_itemsets = self.frequent_itemsets\n",
        "        # If the item is frequent, emit it with its count\n",
        "        if item in frequent_itemsets:\n",
        "            yield frequent_itemsets[item], (count, item)\n",
        "\n",
        "    def reducer_build_fp_tree(self, _, counts_and_items):\n",
        "        # Build the FP-tree\n",
        "        tree = FPTree()\n",
        "        for count, item in counts_and_items:\n",
        "            tree.add(item, count)\n",
        "        # Emit the tree as a JSON object\n",
        "        yield None, tree.to_json()\n",
        "\n",
        "    def mapper_find_patterns(self, _, tree_json):\n",
        "        # Load the tree from the JSON object\n",
        "        tree = FPTree.from_json(tree_json)\n",
        "        # Find the frequent patterns in the tree\n",
        "        patterns = tree.find_frequent_patterns()\n",
        "        # Emit each pattern with a count of 1\n",
        "        for pattern in patterns:\n",
        "            yield pattern, 1\n",
        "\n",
        "    def reducer_output_patterns(self, pattern, counts):\n",
        "        # Sum the counts of the patterns\n",
        "        total_count = sum(counts)\n",
        "        # Emit the pattern and its total count\n",
        "        yield pattern, total_count\n",
        "\n",
        "    def load_frequent_itemsets(self):\n",
        "    # Load the frequent itemsets from a file\n",
        "        with open(\"/content/gdrive/MyDrive/DataSetA.csv\", 'r') as f:\n",
        "            frequent_itemsets = {}\n",
        "            for line in f:\n",
        "                items = tuple(item for item in line.strip().split(','))\n",
        "                # items = tuple(items.split(','))\n",
        "                # count = int(count)\n",
        "                frequent_itemsets[items[0]] = items[1]\n",
        "        # Store the frequent itemsets in the MRJob instance\n",
        "        self.frequent_itemsets = frequent_itemsets\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # MRFPGrowth.run()\n",
        "    inputFile = \"/content/gdrive/MyDrive/DataSetA.csv\"\n",
        "    outFile =  \"flist.csv\"\n",
        "    mr_job = MRFPGrowth(args=[inputFile])\n",
        "    with mr_job.make_runner() as runner:\n",
        "      runner.run()\n",
        "      f = open(outFile, \"w\") \n",
        "      for key, value in mr_job.parse_output(runner.cat_output()):\n",
        "        s = f'{key},{value}'\n",
        "        print(s, file = f)\n",
        "      f.close()\n",
        "\n",
        "    mr_job2 = MRFPGrowth(args=[inputFile])\n",
        "    with mr_job2.make_runner() as runner:\n",
        "      runner.run()\n",
        "      for key, value in mr_job2.parse_output(runner.cat_output()):\n",
        "        print(key,value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI3qPOU0-zz2",
        "outputId": "41947c2f-d0e9-4157-c6bb-c0a0d9c12f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting PFP1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python PFP1.py  '--no-bootstrap-mrjob' \"/content/gdrive/MyDrive/DataSetA.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2IMdMcd_DL_",
        "outputId": "282fad0c-c551-43b8-97cb-6468c8c94070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs specified for inline runner\n",
            "No configs specified for inline runner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yo58aL_KJU0D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}